\documentclass[../main.tex]{subfiles}
\begin{document}

\tikzstyle{block} = [draw, rectangle, text width=2cm, text centered, minimum height=1.2cm, node distance=3cm]
\tikzstyle{bigblock} = [draw, rectangle, text width=2cm, text centered, minimum height=2.2cm, minimum width=3.2cm, node distance=3cm]
\tikzstyle{container} = [draw, rectangle, inner sep=0.3cm]


\section{Introduction}
In the following chapter the theory behind compiler and the build process is introduced. At the end a introduction over the Sconc build framework is reported. The Scons framework is the basic structure upon which the generation of Ecu code is based. 

\section{Compiler}
A compiler is a complex machine that bridges the gap between human readable code and computer readable code.\\
In a model based manner the compiler takes as input source code in a high-level programming language (such as C, C++, Python) and return as a output code in a low level language that compose the executable program. 
\begin{figure}[H]
  \centering
\begin{tikzpicture}
    \node [block, name=text1] {Source code};
    \node [bigblock, right of=text1] (text2) {Compiler};
    \node [block, right of=text2] (text3) {Executable code};
    \draw [->] (text1) -- (text2);
    \draw [->] (text2) -- node {} (text3);
\end{tikzpicture}
    \caption{Compiler}
    \label{fig:compiler}
\end{figure}
In a executable program generated by the compiler we find a list of instruction to follow all written in binary (machine code). The instruction in binary code are needed to connect together the correct circuits in the CPU, by mean of activating (1) ore deactivating (0) certain transistors, and therefor completing the instructions. Since the CPU can only perform operation such as memory read-wright and basic math the compiler does not only need to translate the source code in binary code, but has also to execute a series of operation to adapt the complexity to the CPU. 
The main components of a compiler are the following:
\begin{itemize}
    \item The front end
\end{itemize}
\begin{figure}[]
  \centering
\begin{tikzpicture}

    \node [block, name=text1] {Text1};
    \node [block, right of=text1] (text2) {Text2};
    \node [block, right of=text2] (text3) {Text3};
    \node [block, right of=text3] (text4) {Text4};
    \node [block, right of=text4] (text5) {Text5};
    \node [container,fit=(text2) (text3) (text4)] (container) {};

    \draw [->] (text1) -- (text2);
    \draw [->] (text2) -- node {} (text3);
    \draw [->] (text3) -- node {} (text4);
    \draw [->] (text4) -- node {} (text5);
\end{tikzpicture}
  \caption{Compiler overview structure}
\end{figure}
In order to better visualize the concepts, consider the following example, based on \cite{frametheessence}. 
  \begin{lstlisting}[language=C]
int main() {
   int x;
   x = 3;
}
  \end{lstlisting}
The code has no function, but is useful to better visualize the further developed concepts. 
\subsection{The front end}
The first part of the compiler is the front end. This part read the source program and check the syntax and semantics. Its output is a intermediate form that already interprets most of the language specifics operation. This first step is required because different type of processor may require different "byte representation", but may be sharing the same front end.\\
The steps in which the front end is articulated are the following:
\begin{itemize}
    \item Scanning, During the scanning the individuals characters are read and divided into tokens, and the reserved word are recognised. In the previous example the tokens structure is the following: \texttt{'int', 'main', '(', ')', '\{', '\}', 'int', 'x', ';'...'\}'}. Inside those tokens reserved words are \texttt{'int'}, words like \texttt{'x'} is recognized as numbers and \texttt{'3'} as a number.
    \item Parsing, in this step the syntax is checked and the tokens are organized into a structure tree. \\
        \begin{figure}[H]
            \centering
        \begin{forest}
          forked edges,
          for tree={edge+={-Latex}},
          [\texttt{x = 3}
                [assignment statement
                    [identifier
                        [\texttt{x}]]
                    [\texttt{=}]
                    [expression
                        [number
                            [\texttt{3}]]]
                ]
          ]
        \end{forest}
            \caption{Caption}
            \label{fig:my_label}
        \end{figure}
    \item Semantics analysis, during this step takes as input the syntax tree and check for semantic correctness. This involve variable declaration checking, matching between operators and objects. During this step a table representing what the computer need to keep track is created. 
        \begin{table}[ht]
        \centering
        \begin{tabular}[t]{lcc}
        \hline
        Name & Type & Scope\\
        \hline
        \texttt{main}&funct int&global\\
        \texttt{x}&int &local main\\
        \hline
        \end{tabular}
        \caption{Symbol table}
        \end{table}%
    \item Generation of intermediate representation, the intermediate representation is the output of the front end part. The intermediate representation usually use simple operations on a small set of primitive types. The output looks a lot like MIPS instructions (i.e. Microprocessor Paradigm architecture instructions). The main focus is to create an output that specify the functionality of the program in a source independent form. This allow to have a the next steps as language independents steps. 
\end{itemize}
\cleardoublepage
\end{document}